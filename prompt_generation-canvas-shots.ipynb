{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9aef5ac-707c-43d2-9f57-a5b387c86925",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anthropic                          0.33.0\n",
      "anthropic-bedrock                  0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip list|grep -i anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879dbbba-422b-4a07-9258-f1489e4eea45",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (10.3.0)\n",
      "Collecting python-magic\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting moviepy\n",
      "  Downloading moviepy-2.1.1-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m237.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator<6.0,>=4.0.2 in /Users/tangqy/Library/Python/3.10/lib/python/site-packages (from moviepy) (5.1.1)\n",
      "Collecting imageio<3.0,>=2.5\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m860.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting proglog<=1.0.0\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from moviepy) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from moviepy) (2.0.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0\n",
      "  Downloading imageio-ffmpeg-0.5.1.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (65.5.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from proglog<=1.0.0->moviepy) (4.66.4)\n",
      "Installing collected packages: python-magic, proglog, imageio_ffmpeg, imageio, moviepy\n",
      "\u001b[33m  DEPRECATION: imageio_ffmpeg is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running setup.py install for imageio_ffmpeg ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed imageio-2.36.1 imageio_ffmpeg-0.5.1 moviepy-2.1.1 proglog-0.1.10 python-magic-0.4.27\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install Pillow python-magic moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87b3c05-9ad6-4a58-ae21-c699a18107af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "from botocore.config import Config\n",
    "config = Config(\n",
    "       connect_timeout=1000,\n",
    "    read_timeout=1000,\n",
    ")\n",
    "\n",
    "session = boto3.session.Session(region_name='us-east-1')\n",
    "bedrock_runtime = session.client(service_name = 'bedrock-runtime', \n",
    "                                 config=config)\n",
    "\n",
    "PRO_MODEL_ID = \"us.amazon.nova-pro-v1:0\"\n",
    "LITE_MODEL_ID = \"us.amazon.nova-lite-v1:0\"\n",
    "MICRO_MODEL_ID = \"us.amazon.nova-micro-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb36c95-0cf1-428e-aeee-225d516d3341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "import re\n",
    "def parse(pattern:str, text: str) -> str:\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "        return text.strip()\n",
    "    else:\n",
    "        raise JSONDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d83d4-39ef-491f-aa20-8bcdf1403f2b",
   "metadata": {},
   "source": [
    "## 分镜头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce254fc-f720-47d1-bef8-e7119be8a958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_1 = \\\n",
    "\"\"\"\n",
    "我需要你帮我把以下场景描述拆分成一系列分镜。每个分镜都应该：\n",
    "1. 包含一个清晰的画面重点\n",
    "2. 描述具体的视觉元素(如构图、光线、视角等)\n",
    "3. 适合用于AI图像生成\n",
    "4. 使用简洁的英文描述\n",
    "5. 添加关键的艺术风格和氛围标签\n",
    "6. 镜头不超过3个\n",
    "\n",
    "#注意事项\n",
    "- Prompting for image generation models differs from prompting for large language models (LLMs). Image generation models do not have the ability to reason or interpret explicit commands. Therefore, it's best to phrase your prompt as if it were an image caption rather than a command or conversation.\n",
    "- Consider adding modifiers like aspect ratios, image quality settings, or post-processing instructions to refine the output.\n",
    "- Avoid topics such as pornography, racial discrimination, and toxic words.\n",
    "- Do not use negation words like \"no\", \"not\", \"without\", and so on in your prompt. The model doesn't understand negation in a prompt and attempting to use negation will result in the opposite of what you intend. For example, a prompt such as \"a fruit basket with no bananas\" will actually signal the model to include bananas. Instead, you can use a negative prompt, via the negative prompt, to specify any objects or characteristics that you want to exclude from the image. For example \"bananas\".\n",
    "\n",
    "请将以下场景描述拆分为分镜，并以精简的 JSON 格式输出：\n",
    "{\n",
    "    \"shots\": [\n",
    "        {\n",
    "            \"id\": \"shot_1\",\n",
    "            \"description\": \"场景描述\",\n",
    "            \"composition\": \"构图说明\",\n",
    "            \"lighting\": \"光线说明\",\n",
    "            \"angle\": \"视角说明\",\n",
    "            \"distance\": \"景别说明\",\n",
    "            \"style_tags\": [\"标签1\", \"标签2\", \"标签3\"],\n",
    "            \"prompt\": \"英文提示词\",\n",
    "            \"negative_prompt\": \"(可选)负向提示词\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "##示例##\n",
    "场景描述：一个女孩在黄昏时分走在海边的沙滩上，远处是落日和帆船。\n",
    "\n",
    "输出：\n",
    "{\n",
    "    \"shots\": [\n",
    "        {\n",
    "            \"id\": \"shot_1\",\n",
    "            \"description\": \"远景镜头，展现黄昏海滩的整体氛围\",\n",
    "            \"composition\": \"wide angle composition\",\n",
    "            \"lighting\": \"natural sunset lighting\",\n",
    "            \"angle\": \"eye level\",\n",
    "            \"distance\": \"long shot\",\n",
    "            \"style_tags\": [\"cinematic\", \"golden hour\", \"peaceful\", \"warm colors\"],\n",
    "            \"prompt\": \"wide shot of a beach at sunset, golden hour, sailing boats on horizon, cinematic lighting\",\n",
    "            \"negative_prompt\":\"\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"shot_2\",\n",
    "            \"description\": \"女孩的背影剪影\",\n",
    "            \"composition\": \"rule of thirds\",\n",
    "            \"lighting\": \"backlight\",\n",
    "            \"angle\": \"side view\",\n",
    "            \"distance\": \"medium shot\",\n",
    "            \"style_tags\": [\"atmospheric\", \"moody\", \"dramatic\", \"silhouette\"],\n",
    "            \"prompt\": \"silhouette of a girl walking on beach, sunset backdrop, side view, dramatic lighting\",\n",
    "            \"negative_prompt\":\"wrong leg\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"shot_3\",\n",
    "            \"description\": \"特写镜头展现女孩的表情和周围环境细节\",\n",
    "            \"composition\": \"centered composition\",\n",
    "            \"lighting\": \"side lighting\",\n",
    "            \"angle\": \"eye level\",\n",
    "            \"distance\": \"close-up\",\n",
    "            \"style_tags\": [\"portrait\", \"emotional\", \"soft lighting\", \"intimate\"],\n",
    "            \"prompt\": \"close-up shot of a girl's face, warm sunset light, beach background, soft focus\",\n",
    "            \"negative_prompt\":\"\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c98dd3-528e-49d4-b5c6-09e52b4bd0f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def invoke_nova(system, messages):\n",
    "\n",
    "    # Configure the inference parameters.\n",
    "    inf_params = {\"maxTokens\": 2000, \"topP\": 0.9, \"temperature\": 0.8}\n",
    "\n",
    "    model_response = bedrock_runtime.converse_stream(\n",
    "        modelId=PRO_MODEL_ID, messages=messages, system=system, inferenceConfig=inf_params\n",
    "    )\n",
    "\n",
    "    text = \"\"\n",
    "    stream = model_response.get(\"stream\")\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            if \"contentBlockDelta\" in event:\n",
    "                text += event[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "                print(event[\"contentBlockDelta\"][\"delta\"][\"text\"], end=\"\")\n",
    "    return json.loads(text[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db5bd72-a8bd-4ecb-b911-37db4915b793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "story = \"在一片广袤的科技星空下，AWS如一柄闪耀着银色光芒的利剑静静悬浮。这把利剑的剑身流转着云计算的灵动数据流，剑锋锐利如同切割黎明的第一缕阳光。当我握住剑柄的那一刻，数字化转型的荆棘丛生之路顿时豁然开朗，如同劈开浓雾见晴天。利剑所指之处，道路两旁绽放出创新的繁花，照亮了企业腾飞的征程，恰似黎明前升起的启明星指引着前行的方向。\"\n",
    "story = \"晨曦微光中，连绵的雪峰在地平线上如巨人般矗立，山峦的倒影完美地映照在平静如镜的湖面上。湖水呈现出深邃的蓝绿色调，周围环绕着郁郁葱葱的针叶林，树梢轻轻摇曳。淡淡的晨雾缭绕在山谷间，为整个画面增添了几分神秘与朦胧的意境。远处的云层呈现出柔和的粉紫色，与湖面泛起的金色波光相互辉映，构成一幅震撼人心的自然画卷\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bfa6c8-0c89-4655-b2f0-1959c199b50b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"shots\": [\n",
      "        {\n",
      "            \"id\": \"shot_1\",\n",
      "            \"description\": \"远景镜头，展现晨曦中的雪峰和倒映在湖面上的山峦\",\n",
      "            \"composition\": \"wide angle composition\",\n",
      "            \"lighting\": \"soft morning light\",\n",
      "            \"angle\": \"eye level\",\n",
      "            \"distance\": \"long shot\",\n",
      "            \"style_tags\": [\"cinematic\", \"scenic\", \"serene\", \"natural beauty\"],\n",
      "            \"prompt\": \"wide shot of snow-capped mountains and their reflection in a calm lake at dawn, surrounded by a coniferous forest, soft morning light\",\n",
      "            \"negative_prompt\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"shot_2\",\n",
      "            \"description\": \"中景镜头，突出湖水的深邃蓝绿色调和周围的针叶林\",\n",
      "            \"composition\": \"balanced composition\",\n",
      "            \"lighting\": \"natural ambient light\",\n",
      "            \"angle\": \"slightly elevated\",\n",
      "            \"distance\": \"medium shot\",\n",
      "            \"style_tags\": [\"peaceful\", \"lush\", \"vibrant\", \"forest\"],\n",
      "            \"prompt\": \"medium shot of a serene lake with deep teal-green water, surrounded by lush coniferous trees, natural ambient light\",\n",
      "            \"negative_prompt\": \"\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"shot_3\",\n",
      "            \"description\": \"特写镜头，展现晨雾缭绕在山谷间和柔和的粉紫色云层\",\n",
      "            \"composition\": \"centered composition\",\n",
      "            \"lighting\": \"soft diffused light\",\n",
      "            \"angle\": \"eye level\",\n",
      "            \"distance\": \"close-up\",\n",
      "            \"style_tags\": [\"mystical\", \"dreamy\", \"ethereal\", \"fog\"],\n",
      "            \"prompt\": \"close-up shot of morning mist swirling in a valley with soft pink-purple clouds in the distance, soft diffused light\",\n",
      "            \"negative_prompt\": \"\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```"
     ]
    }
   ],
   "source": [
    "system = [\n",
    "    {\n",
    "        \"text\": system_1\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "         {\"text\": story},\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "         \"role\": \"assistant\",\n",
    "         \"content\": [\n",
    "         {\"text\": \"```json\"},\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "    \n",
    "shots = invoke_nova(system=system,messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c857e410-1667-4c9a-bff0-05c4759b7826",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = [ f\"{p['prompt']} {p['composition']} angle:{p['angle']} {p['distance']} {p['lighting']} {' '.join(p['style_tags'])}\" for p in shots['shots']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46bdcb5f-d7f7-4b39-a381-5a549145d42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "neg_prompts = [p['negative_prompt'] for p in shots['shots']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc881297-0d1c-4b5d-9d4a-e05146339c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "from PIL import Image\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe005a0-a3ef-4ddf-a46b-bd6d17b47ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_image(body):\n",
    "    \"\"\"\n",
    "    Generate an image using Amazon Nova Canvas model on demand.\n",
    "    Args:\n",
    "        body (str) : The request body to use.\n",
    "    Returns:\n",
    "        image_bytes (bytes): The image generated by the model.\n",
    "    \"\"\"\n",
    "    accept = \"application/json\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    response = bedrock_runtime.invoke_model(\n",
    "        body=body, modelId='amazon.nova-canvas-v1:0', accept=accept, contentType=content_type\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    image_bytes_list = []\n",
    "    if \"images\" in response_body:\n",
    "        print(f\"num of images:{len(response_body['images'])}\")\n",
    "        for base64_image in response_body[\"images\"]:\n",
    "            base64_bytes = base64_image.encode('ascii')\n",
    "            image_bytes = base64.b64decode(base64_bytes)\n",
    "            image_bytes_list.append(image_bytes)\n",
    "\n",
    "    finish_reason = response_body.get(\"error\")\n",
    "\n",
    "    if finish_reason is not None:\n",
    "        raise ImageError(f\"Image generation error. Error is {finish_reason}\")\n",
    "\n",
    "    return image_bytes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b035217-d606-4901-8c38-ecfaaebc109c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_variations(reference_image_paths,prompt,negative_prompt,save_filepath):\n",
    "    # Load all reference images as base64.\n",
    "    images = []\n",
    "    for path in reference_image_paths:\n",
    "        with open(path, \"rb\") as image_file:\n",
    "            images.append(base64.b64encode(image_file.read()).decode(\"utf-8\"))\n",
    "\n",
    "    # Configure the inference parameters.\n",
    "    inference_params = {\n",
    "        \"taskType\": \"IMAGE_VARIATION\",\n",
    "        \"imageVariationParams\": {\n",
    "            \"images\": images, # Images to use as reference\n",
    "            \"text\": prompt, \n",
    "            \"similarityStrength\": 0.9,  # Range: 0.2 to 1.0\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,  # Number of variations to generate. 1 to 5.\n",
    "            \"quality\": \"standard\",  # Allowed values are \"standard\" and \"premium\"\n",
    "            \"width\": 1280,  # See README for supported output resolutions\n",
    "            \"height\": 720,  # See README for supported output resolutions\n",
    "            \"cfgScale\": 4.0,  # How closely the prompt will be followed\n",
    "            \"seed\": 0\n",
    "        },\n",
    "    }\n",
    "    if len(negative_prompt):\n",
    "        inference_params['imageVariationParams'][\"negativeText\"] = negative_prompt\n",
    "        \n",
    "    body = json.dumps(inference_params)\n",
    "    try:\n",
    "        image_bytes_ret = generate_image( body=body)\n",
    "        for idx,image_bytes in enumerate(image_bytes_ret):\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            image.save(save_filepath)\n",
    "            print(f\"image saved to {save_filepath}\")\n",
    "            # image.show()\n",
    "    except Exception as err:\n",
    "        print(str(err))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d62f6bf-cd40-4240-b026-252e32f69518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_text2img(prompt,negative_prompt,save_filepath):\n",
    "    textToImageParams =  { \"text\": prompt}\n",
    "    if len(negative_prompt):\n",
    "        textToImageParams[\"negativeText\"] = negative_prompt \n",
    "    body = json.dumps({\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": textToImageParams,\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"height\": 720,\n",
    "            \"width\": 1280,\n",
    "            \"cfgScale\": 6.5,\n",
    "            \"seed\": 0\n",
    "        }\n",
    "    })\n",
    "    try:\n",
    "        image_bytes_ret = generate_image( body=body)\n",
    "        print(f\"num:{len(image_bytes_ret)}\")\n",
    "        # print(f\"image_bytes:{image_bytes_ret[:20]}\")\n",
    "\n",
    "        for idx,image_bytes in enumerate(image_bytes_ret):\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            image.save(save_filepath)  \n",
    "            print(f\"image saved to {save_filepath}\")\n",
    "            # image.show()\n",
    "        return save_filepath\n",
    "\n",
    "    except Exception as err:\n",
    "        print(str(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd1909bc-8a81-44b4-b5be-f71c469d75b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:wide shot of snow-capped mountains and their reflection in a calm lake at dawn, surrounded by a coniferous forest, soft morning light wide angle composition angle:eye level long shot soft morning light cinematic scenic serene natural beauty\n",
      "neg_prompt:\n",
      "num of images:1\n",
      "num:1\n",
      "image saved to shot_images/20241230024507/shot_0.png\n",
      "prompt:medium shot of a serene lake with deep teal-green water, surrounded by lush coniferous trees, natural ambient light balanced composition angle:slightly elevated medium shot natural ambient light peaceful lush vibrant forest\n",
      "neg_prompt:\n",
      "num of images:1\n",
      "image saved to shot_images/20241230024507/shot_1.png\n",
      "prompt:close-up shot of morning mist swirling in a valley with soft pink-purple clouds in the distance, soft diffused light centered composition angle:eye level close-up soft diffused light mystical dreamy ethereal fog\n",
      "neg_prompt:\n",
      "num of images:1\n",
      "image saved to shot_images/20241230024507/shot_2.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "output_dir=os.path.join('shot_images',timestamp)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "image_files = []\n",
    "for idx, prompt, neg_prompt in zip(range(len(prompts)),prompts,neg_prompts):\n",
    "    print(f\"prompt:{prompt}\\nneg_prompt:{neg_prompt}\")\n",
    "    save_path = os.path.join(output_dir,f'shot_{idx}.png')\n",
    "    #第一张图\n",
    "    if not image_files: \n",
    "        generate_text2img(prompt,neg_prompt,save_path)\n",
    "    else:\n",
    "        generate_variations(image_files,prompt,neg_prompt,save_path)\n",
    "    image_files.append(save_path)\n",
    "        \n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0eebc-da0a-45e4-b286-ebb5c2db6e6c",
   "metadata": {},
   "source": [
    "## 优化Reel 提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fd3e304-5788-4203-990e-4cabf2c07f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_2 = \\\n",
    "\"\"\"\n",
    "You are a Prompt rewriting expert for image-to-video models, with expertise in film industry knowledge and skilled at helping users output final text prompts based on input initial frame images and potentially accompanying text prompts. \n",
    "The main goal is to help other models produce better video outputs based on these prompts and initial frame images. Users may input only images or both an image and text prompt, where the text could be in Chinese or English.\n",
    "Your final output should be a single paragraph of English prompt not exceeding 90 words.\n",
    "\n",
    "##You are proficient in the knowledge mentioned in:##\n",
    "-You have a comprehensive understanding of the world, knowing various physical laws and can envision video content showing interactions between all things.\n",
    "-You are imaginative and can envision the most perfect, visually impactful video scenes based on user-input images and prompts.\n",
    "-You possess extensive film industry knowledge as a master director, capable of supplementing the best cinematographic language and visual effects based on user-input images and simple descriptions.\n",
    "\n",
    "\n",
    "##Please follow these guidelines for rewriting prompts:##\n",
    "-Subject: Based on user-uploaded image content, describe the video subject's characteristics in detail, emphasizing details while adjusting according to user's text prompt.\n",
    "-Scene: Detailed description of video background, including location, environment, setting, season, time, etc., emphasizing details.\n",
    "-Emotion and Atmosphere: Description of emotions and overall atmosphere conveyed in the video, referencing the image and user's prompt.\n",
    "-Cinematography: Specify shot types, camera angles, and perspectives, Please refer to the guideline in DocumentPDFmessages.\n",
    "-Visual Effects: Description of the visual style from user-uploaded images, such as Pixar animation, film style, realistic style, 3D animation, including descriptions of color schemes, lighting types, and contrast.\n",
    "\n",
    "##Good Examples##\n",
    "- Prompt: \"Cinematic dolly shot of a juicy cheeseburger with melting cheese, fries, and a condensation-covered cola on a worn diner table. Natural lighting, visible steam and droplets. 4k, photorealistic, shallow depth of field\"\n",
    "- Prompt: \"Arc shot on a salad with dressing, olives and other vegetables; 4k; Cinematic;\"\n",
    "- Prompt: \"First person view of a motorcycle riding through the forest road.\"\n",
    "- Prompt: \"Closeup of a large seashell in the sand. Gentle waves flow around the shell. Camera zoom in.\"\n",
    "- Prompt: \"Clothes hanging on a thread to dry, windy; sunny day; 4k; Cinematic; highest quality;\"\n",
    "- Prompt: \"Slow cam of a man middle age; 4k; Cinematic; in a sunny day; peaceful; highest quality; dolly in;\"\n",
    "- Prompt: \"A mushroom drinking a cup of coffee while sitting on a couch, photorealistic.\"\n",
    "\n",
    "##Ouput instruction##\n",
    "Users may input prompts in Chinese or English, but your final output should be a single English paragraph not exceeding 90 words.\n",
    "Put your reponse in <prompt></prompt>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "354ad16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_3 = \"\"\"\n",
    "You are a Prompt Rewriting Expert for text-to-video models, with extensive knowledge in film and video production. \n",
    "You specialize in helping users improve their text prompts according to specific rules to achieve better model outputs, sometimes modifying the original intent if necessary.\n",
    "\n",
    "##You excel in the following areas:##\n",
    "Comprehensive understanding of the world, physical laws, and various interactive video scenarios\n",
    "Rich imagination to visualize perfect, visually striking video scenes from simple prompts\n",
    "Extensive film industry expertise as a master director, capable of enhancing simple video descriptions with optimal cinematography and visual effects\n",
    "\n",
    "##Your prompt rewriting should follow these guidelines:##\n",
    "Prompting for video generation models differs from prompting for large language models (LLMs).\n",
    "Video generation models do not have the ability to reason or interpret explicit commands.\n",
    "Therefore, it's best to phrase your prompt as if it were an image caption or summary of the video rather than a command or conversation.\n",
    "You may want to include details about the subject, action, environment, lighting, style, and camera motion.\n",
    "\n",
    "-Subject: Add detailed characteristics of video subjects\n",
    "-Scene: Elaborate background details based on context\n",
    "-Emotional atmosphere: Describe the mood and overall ambiance\n",
    "-Visual effects: Define style (e.g., Pixar, cinematic, hyperrealistic, 3D animation) and describe lighting, color tones, and contrast.\n",
    "-Cinematography: Specify shot types, camera angles, and perspectives (avoid complex camera movements),refer to 'Camera Prompt 运镜指南' in DocumentPDFmessages. \n",
    "\n",
    "##Good Examples##\n",
    "- Prompt: \"Cinematic dolly shot of a juicy cheeseburger with melting cheese, fries, and a condensation-covered cola on a worn diner table. Natural lighting, visible steam and droplets. 4k, photorealistic, shallow depth of field\"\n",
    "- Prompt: \"Arc shot on a salad with dressing, olives and other vegetables; 4k; Cinematic;\"\n",
    "- Prompt: \"First person view of a motorcycle riding through the forest road.\"\n",
    "- Prompt: \"Closeup of a large seashell in the sand. Gentle waves flow around the shell. Camera zoom in.\"\n",
    "- Prompt: \"Clothes hanging on a thread to dry, windy; sunny day; 4k; Cinematic; highest quality;\"\n",
    "- Prompt: \"Slow cam of a man middle age; 4k; Cinematic; in a sunny day; peaceful; highest quality; dolly in;\"\n",
    "- Prompt: \"A mushroom drinking a cup of coffee while sitting on a couch, photorealistic.\"\n",
    "\n",
    "##Ouput instruction##\n",
    "Users may input prompts in Chinese or English, but your final output should be a single English paragraph not exceeding 90 words.\n",
    "Put your reponse in <prompt></prompt>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "636a633b-2455-4f5b-9190-dda47d011a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import magic\n",
    "from json import JSONDecodeError\n",
    "import re\n",
    "def img_mime(image_path):\n",
    "    try:\n",
    "        mime = magic.Magic(mime=True)\n",
    "        return mime.from_file(image_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"python-magic detection error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def parse(text: str) -> str:\n",
    "    pattern = r\"<prompt>(.*?)</prompt>\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "        return text.strip()\n",
    "    else:\n",
    "        raise JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e23bb97-055a-4100-9804-4ebdd7a6b186",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_reel_prompt(system,user_prompt,ref_image,doc_bytes):\n",
    "    with open(ref_image, \"rb\") as f:\n",
    "        image = f.read()\n",
    "    mime_type = img_mime(ref_image)\n",
    "\n",
    "    system = [\n",
    "        {\n",
    "            \"text\": system\n",
    "        }\n",
    "    ]\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "             {\n",
    "                \"document\": {\n",
    "                    \"format\": \"pdf\",\n",
    "                    \"name\": \"DocumentPDFmessages\",\n",
    "                    \"source\": {\n",
    "                        \"bytes\": doc_bytes\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\"image\": {\"format\": mime_type.split('/')[1], \"source\": {\"bytes\": image}}},\n",
    "             {\"text\": user_prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Configure the inference parameters.\n",
    "    inf_params = {\"maxTokens\": 2000, \"topP\": 0.9, \"temperature\": 0.5}\n",
    "\n",
    "\n",
    "    model_response = bedrock_runtime.converse_stream(\n",
    "        modelId=LITE_MODEL_ID, messages=messages, system=system, inferenceConfig=inf_params\n",
    "    )\n",
    "\n",
    "    text = \"\"\n",
    "    stream = model_response.get(\"stream\")\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            if \"contentBlockDelta\" in event:\n",
    "                text += event[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "                print(event[\"contentBlockDelta\"][\"delta\"][\"text\"], end=\"\")\n",
    "    return parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffd303fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_reel_prompt_no_img(system,user_prompt,doc_bytes):\n",
    "    system = [\n",
    "        {\n",
    "            \"text\": system\n",
    "        }\n",
    "    ]\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "             {\n",
    "                \"document\": {\n",
    "                    \"format\": \"pdf\",\n",
    "                    \"name\": \"DocumentPDFmessages\",\n",
    "                    \"source\": {\n",
    "                        \"bytes\": doc_bytes\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "             {\"text\": user_prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Configure the inference parameters.\n",
    "    inf_params = {\"maxTokens\": 2000, \"topP\": 0.9, \"temperature\": 0.5}\n",
    "\n",
    "\n",
    "    model_response = bedrock_runtime.converse_stream(\n",
    "        modelId=LITE_MODEL_ID, messages=messages, system=system, inferenceConfig=inf_params\n",
    "    )\n",
    "\n",
    "    text = \"\"\n",
    "    stream = model_response.get(\"stream\")\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            if \"contentBlockDelta\" in event:\n",
    "                text += event[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "                print(event[\"contentBlockDelta\"][\"delta\"][\"text\"], end=\"\")\n",
    "    return parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb329df0-17fb-44c5-a9db-ad9950529b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Amazon_Nova_Reel.pdf\", \"rb\") as file:\n",
    "    doc_bytes = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad8795",
   "metadata": {},
   "source": [
    "### option 1， 全部采用image 2 video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97498fa4-40e9-4890-8cbd-bfbfd2903f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "展现整体晨曦景象，远景镜头\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'optimize_reel_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p,ref_img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(shots[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshots\u001b[39m\u001b[38;5;124m'\u001b[39m],image_files):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[0;32m----> 4\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_reel_prompt\u001b[49m(system_2,p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m],ref_img,doc_bytes)\n\u001b[1;32m      5\u001b[0m     reel_prompts\u001b[38;5;241m.\u001b[39mappend(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimize_reel_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "reel_prompts = []\n",
    "for p,ref_img in zip(shots['shots'],image_files):\n",
    "    print(p['description'] )\n",
    "    text = optimize_reel_prompt(system_2,p['description'],ref_img,doc_bytes)\n",
    "    reel_prompts.append(text)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee3098",
   "metadata": {},
   "source": [
    "### option 2， 只对中间图用image 2 video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3494f525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS利剑静静悬浮在科技星空下\n",
      "<prompt>A majestic sword hovers serenely in a futuristic sky filled with advanced technology and glowing clouds, creating a sense of awe and wonder. The scene is captured with a First Person View Aerial shot, zooming in slowly to highlight the intricate details of the sword and its radiant aura. The video is rendered in Ultra HD, 8K resolution, ensuring crisp and photorealistic visuals. The atmosphere is cinematic, with a harmonious blend of warm and cool tones, evoking a sense of epic adventure.</prompt>数字化转型的荆棘丛生之路豁然开朗\n",
      "<prompt>First Person View Aerial, approaching a grand luxury resort complex at dusk. The camera dollys in, revealing ornate beige buildings with clock towers and domes, set against a backdrop of manicured gardens and distant mountains. The sky transitions beautifully from pink to purple as the sun sets. Warm lights from windows and pathways enhance the cinematic quality. Ultra HD, 8K resolution, with crisp details and highest resolution.</prompt>创新的繁花绽放，照亮企业腾飞的征程\n",
      "<prompt>A dynamic aerial shot of a grand luxury resort complex at dusk, with ornate beige buildings featuring clock towers and domes, symmetrical architecture, and manicured gardens in the foreground. The scene captures distant mountains, a pink and purple sunset sky, and warm lights from windows and pathways. The camera performs a dolly in shot, enhancing the cinematic quality with ultra HD, 8K resolution and crisp details.</prompt>"
     ]
    }
   ],
   "source": [
    "reel_prompts = []\n",
    "idx = 0\n",
    "for p,ref_img in zip(shots['shots'],image_files):\n",
    "    print(p['description'] )\n",
    "    if idx == 1:\n",
    "        text = optimize_reel_prompt_no_img(system_2,p['description'],doc_bytes)\n",
    "    else:\n",
    "        text = optimize_reel_prompt(system_2,p['description'],ref_img,doc_bytes)\n",
    "    reel_prompts.append(text)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c8bbda0-709e-423c-a3f5-713e342c755f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A majestic sword hovers serenely in a futuristic sky filled with advanced technology and glowing clouds, creating a sense of awe and wonder. The scene is captured with a First Person View Aerial shot, zooming in slowly to highlight the intricate details of the sword and its radiant aura. The video is rendered in Ultra HD, 8K resolution, ensuring crisp and photorealistic visuals. The atmosphere is cinematic, with a harmonious blend of warm and cool tones, evoking a sense of epic adventure.',\n",
       " 'First Person View Aerial, approaching a grand luxury resort complex at dusk. The camera dollys in, revealing ornate beige buildings with clock towers and domes, set against a backdrop of manicured gardens and distant mountains. The sky transitions beautifully from pink to purple as the sun sets. Warm lights from windows and pathways enhance the cinematic quality. Ultra HD, 8K resolution, with crisp details and highest resolution.',\n",
       " 'A dynamic aerial shot of a grand luxury resort complex at dusk, with ornate beige buildings featuring clock towers and domes, symmetrical architecture, and manicured gardens in the foreground. The scene captures distant mountains, a pink and purple sunset sky, and warm lights from windows and pathways. The camera performs a dolly in shot, enhancing the cinematic quality with ultra HD, 8K resolution and crisp details.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reel_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed9ce9-986a-40de-9454-9645d756c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = \"s3://sagemaker-us-east-1-687912291502/video/output/\"\n",
    "bedrock_runtime = session.client(\"bedrock-runtime\")\n",
    "\n",
    "def generate_video(bucket,text_prompt,ref_image = None):\n",
    "    model_input = {\n",
    "        \"taskType\": \"TEXT_VIDEO\",\n",
    "        \"textToVideoParams\": {\n",
    "            \"text\": text_prompt,\n",
    "        },\n",
    "        \"videoGenerationConfig\": {\n",
    "            \"durationSeconds\": 6,\n",
    "            \"fps\": 24,\n",
    "            \"dimension\": \"1280x720\",\n",
    "            \"seed\": 0,  # Change the seed to get a different result\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if ref_image:\n",
    "        with open(ref_image, \"rb\") as f:\n",
    "            image = f.read()\n",
    "            input_image_base64 = base64.b64encode(image).decode(\"utf-8\")\n",
    "            model_input['textToVideoParams']['images'] = [\n",
    "            {\n",
    "                \"format\": img_mime(ref_image).split('/')[1],\n",
    "                \"source\": {\n",
    "                    \"bytes\": input_image_base64\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "    try:\n",
    "        # Start the asynchronous video generation job.\n",
    "        invocation = bedrock_runtime.start_async_invoke(\n",
    "            modelId=\"amazon.nova-reel-v1:0\",\n",
    "            modelInput=model_input,\n",
    "            outputDataConfig={\n",
    "                \"s3OutputDataConfig\": {\n",
    "                    \"s3Uri\": BUCKET\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        return invocation\n",
    "\n",
    "    except Exception as e:\n",
    "        # Implement error handling here.\n",
    "        message = e.response[\"Error\"][\"Message\"]\n",
    "        print(f\"Error: {message}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b072c4f-8373-420a-bc8b-a533b4bd20ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_video_batch(prompts):\n",
    "    invocation_arns = []\n",
    "    for prompt,image_file in zip(prompts,image_files):\n",
    "        invocation = generate_video(bucket= BUCKET, text_prompt = prompt,ref_image=image_file)\n",
    "        invocation_arns.append(invocation['invocationArn'])\n",
    "    return invocation_arns\n",
    "\n",
    "#只对第二张图用ref image\n",
    "def generate_video_batch_2(prompts):\n",
    "    invocation_arns = []\n",
    "    idx = 0\n",
    "    for prompt,image_file in zip(prompts,image_files):\n",
    "        if idx == 1:\n",
    "            invocation = generate_video(bucket= BUCKET, text_prompt = prompt,ref_image=image_file)\n",
    "        else:\n",
    "            invocation = generate_video(bucket= BUCKET, text_prompt = prompt,ref_image=None)\n",
    "        invocation_arns.append(invocation['invocationArn'])\n",
    "        idx += 1\n",
    "    return invocation_arns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e457aaa-2503-47fc-b37f-3f04cc2e4e80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#全部视频使用ref image\n",
    "# invocation_arns = generate_video_batch(reel_prompts)\n",
    "\n",
    "#只对中间视频用ref image\n",
    "invocation_arns = generate_video_batch_2(reel_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66c7fd85-c393-4c78-893a-538656d825cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arn:aws:bedrock:us-east-1:434444145045:async-invoke/zvp0acj8yp66',\n",
       " 'arn:aws:bedrock:us-east-1:434444145045:async-invoke/2whq3cn3taxz',\n",
       " 'arn:aws:bedrock:us-east-1:434444145045:async-invoke/q8fdq8era4pe']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invocation_arns=['arn:aws:bedrock:us-east-1:434444145045:async-invoke/2p9mjzs41cu7',\n",
    "#  'arn:aws:bedrock:us-east-1:434444145045:async-invoke/lgnytip3nrck',\n",
    "#  'arn:aws:bedrock:us-east-1:434444145045:async-invoke/7udalld4x732',\n",
    "#  'arn:aws:bedrock:us-east-1:434444145045:async-invoke/3n1ujwqbltrr']\n",
    "invocation_arns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40992c61-46fd-40f9-9835-c96bc9a0292e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fetch_job_status(invocation_arns):\n",
    "    final_responses = []\n",
    "    for invocation in invocation_arns:\n",
    "        while 1:\n",
    "            response = bedrock_runtime.get_async_invoke(\n",
    "                invocationArn=invocation\n",
    "            )\n",
    "            status = response[\"status\"]\n",
    "            print(f\"{invocation}: {status}\")\n",
    "            time.sleep(5)\n",
    "            if not status == 'InProgress':\n",
    "                final_responses.append(response)\n",
    "                break\n",
    "    return final_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0e09f1cd-385a-4eb3-be7c-9f79c832cf99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:bedrock:us-east-1:434444145045:async-invoke/zvp0acj8yp66: Completed\n",
      "arn:aws:bedrock:us-east-1:434444145045:async-invoke/2whq3cn3taxz: Completed\n",
      "arn:aws:bedrock:us-east-1:434444145045:async-invoke/q8fdq8era4pe: Completed\n"
     ]
    }
   ],
   "source": [
    "final_responses = fetch_job_status(invocation_arns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "002d4c69-b962-49b1-be27-d1eac726f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "def random_string_name(length=12):\n",
    "    return ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "def download_video_from_s3(s3_uri, local_path):\n",
    "    \"\"\"\n",
    "    Download a video file from S3 to local storage\n",
    "    \n",
    "    Parameters:\n",
    "    s3_uri (str): S3 URI in format 's3://bucket-name/path/to/video.mp4'\n",
    "    local_path (str): Local path where the video will be saved\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize S3 client\n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # Parse S3 URI to get bucket and key\n",
    "        if not s3_uri.startswith('s3://'):\n",
    "            raise ValueError(\"Invalid S3 URI format. Must start with 's3://'\")\n",
    "        \n",
    "        # Remove 's3://' and split into bucket and key\n",
    "        path_parts = s3_uri[5:].split('/', 1)\n",
    "        if len(path_parts) != 2:\n",
    "            raise ValueError(\"Invalid S3 URI format\")\n",
    "        \n",
    "        bucket_name = path_parts[0]\n",
    "        s3_key = path_parts[1]\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(local_path, exist_ok=True)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        fname = timestamp+random_string_name()+'.mp4'\n",
    "        # Download the file\n",
    "        print(f\"Downloading {s3_uri} to {local_path}/{fname}\")\n",
    "        s3_client.download_file(bucket_name, s3_key, local_path+'/'+fname)\n",
    "        print(\"Download completed successfully!\")\n",
    "        \n",
    "        return f\"{local_path}/{fname}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c856bf0-d840-46f8-a24a-88a092b28ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading s3://bedrock-video-generation-us-east-1-jlvyiv/zvp0acj8yp66/output.mp4 to ./generated_videos/20241227133909j7t4s82sn23r.mp4\n",
      "Download completed successfully!\n",
      "Downloading s3://bedrock-video-generation-us-east-1-jlvyiv/2whq3cn3taxz/output.mp4 to ./generated_videos/202412271339140fbbafuekyf9.mp4\n",
      "Download completed successfully!\n",
      "Downloading s3://bedrock-video-generation-us-east-1-jlvyiv/q8fdq8era4pe/output.mp4 to ./generated_videos/20241227133918jdw3vlqxa6cv.mp4\n",
      "Download completed successfully!\n"
     ]
    }
   ],
   "source": [
    "video_files = []\n",
    "for response in final_responses:\n",
    "    output_uri = response['outputDataConfig']['s3OutputDataConfig']['s3Uri']+'/output.mp4'\n",
    "    file_name = download_video_from_s3(output_uri,'./generated_videos')\n",
    "    video_files.append(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9945110",
   "metadata": {},
   "source": [
    "## stitch videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "17119ef5-5805-4371-ad8f-c7de1707c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip, CompositeVideoClip\n",
    "def stitch_videos(video1_path: str, video2_path: str, output_path: str):\n",
    "    \"\"\"\n",
    "    Stitches two videos together and saves the result to a new file.\n",
    "\n",
    "    Args:\n",
    "        video1_path (str): The file path to the first video.\n",
    "        video2_path (str): The file path to the second video.\n",
    "        output_path (str): The file path to save the stitched video.\n",
    "    \"\"\"\n",
    "    # Load the video clips\n",
    "    clip1 = VideoFileClip(video1_path)\n",
    "    clip2 = VideoFileClip(video2_path)\n",
    "\n",
    "    final_clip = [\n",
    "        clip1,\n",
    "        clip2.with_start(clip1.duration),\n",
    "    ]\n",
    "\n",
    "    # Concatenate the clips\n",
    "    final_clip = CompositeVideoClip(final_clip)\n",
    "\n",
    "    # Write the result\n",
    "    final_clip.write_videofile(output_path)\n",
    "\n",
    "    # Clean up\n",
    "    clip1.close()\n",
    "    clip2.close()\n",
    "    final_clip.close()\n",
    "    print(f\"Stitched video saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b38c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video ./generated_videos/7c26vbm53ki8.mp4.\n",
      "MoviePy - Writing video ./generated_videos/7c26vbm53ki8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ./generated_videos/7c26vbm53ki8.mp4\n",
      "Stitched video saved to ./generated_videos/7c26vbm53ki8.mp4\n",
      "MoviePy - Building video ./generated_videos/nvqcbxt4qe46.mp4.\n",
      "MoviePy - Writing video ./generated_videos/nvqcbxt4qe46.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame_index:  76%|███████▌  | 327/433 [00:06<00:02, 51.53it/s, now=None]"
     ]
    }
   ],
   "source": [
    "generated_fname = None\n",
    "for idx in range(len(video_files)-1):\n",
    "    output_path = video_files[0].rsplit(\"/\",1)[0]\n",
    "    if not generated_fname:\n",
    "        generated_fname = stitch_videos(video_files[idx],video_files[idx+1],os.path.join(output_path,random_string_name()+'.mp4'))\n",
    "    else:\n",
    "        generated_fname = stitch_videos(generated_fname,video_files[idx+1],os.path.join(output_path,random_string_name()+'.mp4'))\n",
    "print(f\"Final stitch video:{generated_fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61dec5c",
   "metadata": {},
   "source": [
    "### add caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "077e9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import TextClip\n",
    "def add_timed_captions(video_path, output_path, captions,font='./yahei.ttf'):\n",
    "    # Load the video\n",
    "    video = VideoFileClip(video_path)\n",
    "    \n",
    "    # Create text clips for each caption\n",
    "    txt_clips = []\n",
    "    \n",
    "    for caption in captions:\n",
    "        text, start_time, end_time = caption\n",
    "        txt_clip = TextClip(text=text, font_size=50, color='white', font=font,text_align='center',margin=(20,20))\n",
    "        txt_clip = txt_clip.with_position('bottom').with_start(start_time).with_end(end_time)\n",
    "        txt_clips.append(txt_clip)\n",
    "    \n",
    "    # Combine video and all text clips\n",
    "    final_video = CompositeVideoClip([video] + txt_clips)\n",
    "    \n",
    "    # Write output video\n",
    "    final_video.write_videofile(output_path)\n",
    "    \n",
    "    # Close clips\n",
    "    video.close()\n",
    "    final_video.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e488dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_caption(text):\n",
    "    delimiters = [',', '，', '。', '.', '!', '！', '?', '？', ';', '；', ' ', '\\n', '\\t']\n",
    "    pattern = '|'.join(map(re.escape, delimiters))\n",
    "    parts = re.split(pattern, text)\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0510aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AWS利剑静静悬浮在科技星空下', 0, 6),\n",
       " ('数字化转型的荆棘丛生之路豁然开朗', 6, 12),\n",
       " ('创新的繁花绽放', 12, 15),\n",
       " ('照亮企业腾飞的征程', 15, 18)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "duration = 6\n",
    "captions = []\n",
    "for idx, p in enumerate(shots['shots']):\n",
    "    desc_arr = split_caption(p['description'])\n",
    "    sub_duration = math.ceil(duration/len(desc_arr))\n",
    "    for idy,sub_desc in enumerate(desc_arr):\n",
    "        captions.append((desc_arr[idy],idx*duration+idy*sub_duration,idx*duration+(idy+1)*sub_duration))\n",
    "\n",
    "captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "595e4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# captions = [ (p['description'],idx*duration,(idx+1)*duration) for idx, p in enumerate(shots['shots'])]\n",
    "# captions = [('广袤的科技星空中', 0, 3),\n",
    "#  ('AWS如一柄闪耀着银色光芒的利剑静静悬浮', 3, 6),\n",
    "#  ('利剑的剑身流转着云计算的灵动数据流', 6, 12),\n",
    "#  ('当我握住剑柄的那一刻', 12, 15),\n",
    "#  ('数字化转型的荆棘丛生之路顿时豁然开朗', 15, 18),\n",
    "#  ('利剑所指之处', 18, 20),\n",
    "#  ('道路两旁绽放出创新的繁花', 20, 22),\n",
    "#  ('照亮了企业腾飞的征程', 22, 24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c437ec77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video ./generated_videos/t870rwsq13q6_caption.mp4.\n",
      "MoviePy - Writing video ./generated_videos/t870rwsq13q6_caption.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready ./generated_videos/t870rwsq13q6_caption.mp4\n"
     ]
    }
   ],
   "source": [
    "caption_video_file = os.path.splitext(generated_fname)[0]+\"_caption.mp4\"\n",
    "add_timed_captions(generated_fname,caption_video_file,captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8be8c98b-e74b-4724-a807-d16994b4599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./generated_videos/t870rwsq13q6_caption.mp4\" controls  width=\"1280\"  height=\"720\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video, HTML\n",
    "\n",
    "Video(caption_video_file,width=1280, height=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef49648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
